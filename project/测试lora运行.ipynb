{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc1746d5-b0b4-4a8b-8932-3bfabff8ad15",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-09-02T15:23:08.548847Z",
     "iopub.status.busy": "2024-09-02T15:23:08.548520Z",
     "iopub.status.idle": "2024-09-02T15:25:41.514518Z",
     "shell.execute_reply": "2024-09-02T15:25:41.513982Z",
     "shell.execute_reply.started": "2024-09-02T15:23:08.548824Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-02 23:23:11.495852: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-09-02 23:23:11.506814: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-09-02 23:23:11.520860: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-09-02 23:23:11.525035: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-09-02 23:23:11.535667: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-02 23:23:12.402903: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/usr/local/lib/python3.10/site-packages/_distutils_hack/__init__.py:55: UserWarning: Reliance on distutils from stdlib is deprecated. Users must rely on setuptools to provide the distutils module. Avoid importing distutils or import setuptools first, and avoid setting SETUPTOOLS_USE_DISTUTILS=stdlib. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38a9c5217f354c16a57f908b001304f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "根据题目中的规则，我们可以逐步插入数字到空的二叉搜索树中：\n",
      "\n",
      "1. 首先插入5，树变为：tree(5, nil, nil)\n",
      "2. 插入9，树变为：tree(5, nil, tree(9, nil, nil))\n",
      "3. 插入2，树变为：tree(5, tree(2, nil, nil), tree(9, nil, nil))\n",
      "4. 插入10，树变为：tree(5, tree(2, nil, nil), tree(9, nil, tree(10, nil, nil)))\n",
      "5. 插入11，树变为：tree(5, tree(2, nil, nil), tree(9, nil, tree(10, nil, tree(11, nil, nil))))\n",
      "\n",
      "因此，正确的树结构是：\n",
      "\n",
      "tree(5, tree(2, nil, nil), tree(9, nil, tree(10, nil, tree(11, nil, nil))))\n",
      "\n",
      "答案是：B\n",
      "[2024-09-02 23:24:28,230] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "\u001b[93m [WARNING] \u001b[0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH\n",
      "\u001b[93m [WARNING] \u001b[0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.3\n",
      "\u001b[93m [WARNING] \u001b[0m using untested triton version (2.3.1), only 1.0.0 is known to be compatible\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('./model/Meta-Llama-3.1-8B-Instruct-lora/tokenizer_config.json',\n",
       " './model/Meta-Llama-3.1-8B-Instruct-lora/special_tokens_map.json',\n",
       " './model/Meta-Llama-3.1-8B-Instruct-lora/tokenizer.json')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "from peft import PeftModel\n",
    "\n",
    "output_dir=\"./output/llama3_instruct_lora/20240818\"\n",
    "\n",
    "mode_path = \"./models/Meta-Llama-3.1-8B-Instruct/LLM-Research\"\n",
    "lora_path = f'{output_dir}/checkpoint-700' # 这里改称你的 lora 输出对应 checkpoint 地址\n",
    "\n",
    "# 加载tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(mode_path, trust_remote_code=True)\n",
    "\n",
    "# 加载模型\n",
    "model = AutoModelForCausalLM.from_pretrained(mode_path, device_map=\"auto\",torch_dtype=torch.float16, trust_remote_code=True).eval()\n",
    "\n",
    "# 加载lora权重\n",
    "model = PeftModel.from_pretrained(model, model_id=lora_path)\n",
    "\n",
    "prompt = '''你是一个逻辑推理专家，擅长解决逻辑推理问题。以下是一个逻辑推理的题目，形式为单项选择题。所有的问题都是（close-world assumption）闭世界假设，即未观测事实都为假。请逐步分析问题并在最后一行输出答案，最后一行的格式为\"答案是：A\"。\n",
    "题目如下：\\n\\n### 题目:\\n假设您需要构建一个二叉搜索树，其中每个节点或者是一个空的节点（称为\"空节点\"），或者是一个包含一个整数值和两个子树的节点（称为\"数值节点\"）。以下是构建这棵树的规则：\\n\\n1. 树中不存在重复的元素。\\n2. 对于每个数值节点，其左子树的所有值都小于该节点的值，其右子树的所有值都大于该节点的值。\\n3. 插入一个新值到一个\"空节点\"时，该\"空节点\"会被一个包含新值的新的数值节点取代。\\n4. 插入一个已存在的数值将不会改变树。\\n\\n请基于以上规则，回答以下选择题：\n",
    "\\n\\n### 问题:\\n选择题 1：\\n给定一个空的二叉搜索树，插入下列数字: [5, 9, 2, 10, 11, 3]，下面哪个选项正确描述了结果树的结构？\\nA. tree(5, tree(2, tree(3, nil, nil), nil), tree(9, tree(10, nil, nil), tree(11, nil, nil)))\\nB. tree(5, tree(2, nil, tree(3, nil, nil)), tree(9, nil, tree(10, nil, tree(11, nil, nil))))\\nC. tree(5, tree(3, tree(2, nil, nil), nil), tree(9, nil, tree(10, tree(11, nil, nil), nil)))\\nD. tree(5, nil, tree(2, nil, tree(3, nil, nil)), tree(9, tree(11, nil, nil), tree(10, nil, nil)))'''\n",
    "inputs = tokenizer.apply_chat_template([{\"role\": \"system\", \"content\": \"你是一个逻辑推理专家，擅长解决逻辑推理问题。以下是一个逻辑推理的题目，形式为单项选择题。所有的问题都是（close-world assumption）闭世界假设，即未观测事实都为假。请逐步分析问题并在最后一行输出答案，最后一行的格式为\\\"答案是：A。\"},{\"role\": \"user\", \"content\": prompt}],\n",
    "                                       add_generation_prompt=True,\n",
    "                                       tokenize=True,\n",
    "                                       return_tensors=\"pt\",\n",
    "                                       return_dict=True\n",
    "                                       ).to('cuda')\n",
    "#tensor_gpu = tensor.to('cuda:0')\n",
    "\n",
    "gen_kwargs = {\"max_length\": 2500, \"do_sample\": True, \"top_k\": 1}\n",
    "with torch.no_grad():\n",
    "    outputs = model.generate(**inputs, **gen_kwargs)\n",
    "    outputs = outputs[:, inputs['input_ids'].shape[1]:]\n",
    "    print(tokenizer.decode(outputs[0], skip_special_tokens=True))\n",
    "\n",
    "\n",
    "# In[2]:\n",
    "\n",
    "\n",
    "# 模型合并存储\n",
    "\n",
    "new_model_directory = \"./model/Meta-Llama-3.1-8B-Instruct-lora\"\n",
    "merged_model = model.merge_and_unload()\n",
    "# 将权重保存为safetensors格式的权重, 且每个权重文件最大不超过2GB(2048MB)\n",
    "merged_model.save_pretrained(new_model_directory, max_shard_size=\"2048MB\", safe_serialization=True)\n",
    "# 将tokenizer也保存到 merge_model_dir\n",
    "tokenizer.save_pretrained(new_model_directory)\n",
    "\n",
    "\n",
    "\n",
    "# ## 这里运行完请重启notebook\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c04431e-28de-46ca-a541-5f9762b5bc1d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
