{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c049ac94-3a85-4c3b-8da5-9fabfd10114e",
   "metadata": {
    "ExecutionIndicator": {
     "show": false
    },
    "execution": {
     "iopub.execute_input": "2024-07-27T16:09:07.493223Z",
     "iopub.status.busy": "2024-07-27T16:09:07.492896Z",
     "iopub.status.idle": "2024-07-27T16:10:40.131056Z",
     "shell.execute_reply": "2024-07-27T16:10:40.130348Z",
     "shell.execute_reply.started": "2024-07-27T16:09:07.493202Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://mirrors.cloud.aliyuncs.com/pypi/simple\n",
      "\n",
      "Collecting modelscope==1.9.5\n",
      "\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/ac/05/75b5d750608d7354dc3dd023dca7101e5f3b4645cb3e5b816536d472a058/modelscope-1.9.5-py3-none-any.whl (5.4 MB)\n",
      "\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m51.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\n",
      "\u001b[?25hRequirement already satisfied: addict in /opt/conda/lib/python3.10/site-packages (from modelscope==1.9.5) (2.4.0)\n",
      "\n",
      "Requirement already satisfied: attrs in /opt/conda/lib/python3.10/site-packages (from modelscope==1.9.5) (23.2.0)\n",
      "\n",
      "Collecting datasets<=2.13.0,>=2.8.0 (from modelscope==1.9.5)\n",
      "\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/17/d8/f808e32ed7fa86617b9ac7a37b7dcff894c839108c4871cc33ffc4e65b7d/datasets-2.13.0-py3-none-any.whl (485 kB)\n",
      "\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m485.6/485.6 kB\u001b[0m \u001b[31m85.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\n",
      "\u001b[?25hRequirement already satisfied: einops in /opt/conda/lib/python3.10/site-packages (from modelscope==1.9.5) (0.7.0)\n",
      "\n",
      "Requirement already satisfied: filelock>=3.3.0 in /opt/conda/lib/python3.10/site-packages (from modelscope==1.9.5) (3.13.1)\n",
      "\n",
      "Requirement already satisfied: gast>=0.2.2 in /opt/conda/lib/python3.10/site-packages (from modelscope==1.9.5) (0.5.4)\n",
      "\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from modelscope==1.9.5) (1.26.3)\n",
      "\n",
      "Requirement already satisfied: oss2 in /opt/conda/lib/python3.10/site-packages (from modelscope==1.9.5) (2.18.4)\n",
      "\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from modelscope==1.9.5) (2.2.0)\n",
      "\n",
      "Requirement already satisfied: Pillow>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from modelscope==1.9.5) (10.2.0)\n",
      "\n",
      "Requirement already satisfied: pyarrow!=9.0.0,>=6.0.0 in /opt/conda/lib/python3.10/site-packages (from modelscope==1.9.5) (15.0.0)\n",
      "\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/conda/lib/python3.10/site-packages (from modelscope==1.9.5) (2.8.2)\n",
      "\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from modelscope==1.9.5) (6.0.1)\n",
      "\n",
      "Requirement already satisfied: requests>=2.25 in /opt/conda/lib/python3.10/site-packages (from modelscope==1.9.5) (2.31.0)\n",
      "\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from modelscope==1.9.5) (1.11.4)\n",
      "\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from modelscope==1.9.5) (68.0.0)\n",
      "\n",
      "Requirement already satisfied: simplejson>=3.3.0 in /opt/conda/lib/python3.10/site-packages (from modelscope==1.9.5) (3.19.2)\n",
      "\n",
      "Requirement already satisfied: sortedcontainers>=1.5.9 in /opt/conda/lib/python3.10/site-packages (from modelscope==1.9.5) (2.4.0)\n",
      "\n",
      "Requirement already satisfied: tqdm>=4.64.0 in /opt/conda/lib/python3.10/site-packages (from modelscope==1.9.5) (4.65.0)\n",
      "\n",
      "Requirement already satisfied: urllib3>=1.26 in /opt/conda/lib/python3.10/site-packages (from modelscope==1.9.5) (1.26.16)\n",
      "\n",
      "Requirement already satisfied: yapf in /opt/conda/lib/python3.10/site-packages (from modelscope==1.9.5) (0.30.0)\n",
      "\n",
      "Collecting dill<0.3.7,>=0.3.0 (from datasets<=2.13.0,>=2.8.0->modelscope==1.9.5)\n",
      "\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/be/e3/a84bf2e561beed15813080d693b4b27573262433fced9c1d1fea59e60553/dill-0.3.6-py3-none-any.whl (110 kB)\n",
      "\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m38.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\n",
      "\u001b[?25hRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets<=2.13.0,>=2.8.0->modelscope==1.9.5) (3.4.1)\n",
      "\n",
      "Requirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets<=2.13.0,>=2.8.0->modelscope==1.9.5) (0.70.15)\n",
      "\n",
      "Requirement already satisfied: fsspec>=2021.11.1 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]>=2021.11.1->datasets<=2.13.0,>=2.8.0->modelscope==1.9.5) (2023.10.0)\n",
      "\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets<=2.13.0,>=2.8.0->modelscope==1.9.5) (3.9.3)\n",
      "\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.11.0 in /opt/conda/lib/python3.10/site-packages (from datasets<=2.13.0,>=2.8.0->modelscope==1.9.5) (0.20.3)\n",
      "\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets<=2.13.0,>=2.8.0->modelscope==1.9.5) (23.1)\n",
      "\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.1->modelscope==1.9.5) (1.16.0)\n",
      "\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.25->modelscope==1.9.5) (2.0.4)\n",
      "\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.25->modelscope==1.9.5) (3.4)\n",
      "\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.25->modelscope==1.9.5) (2023.11.17)\n",
      "\n",
      "Requirement already satisfied: crcmod>=1.7 in /opt/conda/lib/python3.10/site-packages (from oss2->modelscope==1.9.5) (1.7)\n",
      "\n",
      "Requirement already satisfied: pycryptodome>=3.4.7 in /opt/conda/lib/python3.10/site-packages (from oss2->modelscope==1.9.5) (3.20.0)\n",
      "\n",
      "Requirement already satisfied: aliyun-python-sdk-kms>=2.4.1 in /opt/conda/lib/python3.10/site-packages (from oss2->modelscope==1.9.5) (2.16.2)\n",
      "\n",
      "Requirement already satisfied: aliyun-python-sdk-core>=2.13.12 in /opt/conda/lib/python3.10/site-packages (from oss2->modelscope==1.9.5) (2.15.1)\n",
      "\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->modelscope==1.9.5) (2023.4)\n",
      "\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->modelscope==1.9.5) (2023.4)\n",
      "\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.9.3 in /opt/conda/lib/python3.10/site-packages (from aliyun-python-sdk-core>=2.13.12->oss2->modelscope==1.9.5) (0.10.0)\n",
      "\n",
      "Requirement already satisfied: cryptography>=2.6.0 in /opt/conda/lib/python3.10/site-packages (from aliyun-python-sdk-core>=2.13.12->oss2->modelscope==1.9.5) (41.0.3)\n",
      "\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets<=2.13.0,>=2.8.0->modelscope==1.9.5) (1.3.1)\n",
      "\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets<=2.13.0,>=2.8.0->modelscope==1.9.5) (1.4.1)\n",
      "\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets<=2.13.0,>=2.8.0->modelscope==1.9.5) (6.0.4)\n",
      "\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets<=2.13.0,>=2.8.0->modelscope==1.9.5) (1.9.4)\n",
      "\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets<=2.13.0,>=2.8.0->modelscope==1.9.5) (4.0.3)\n",
      "\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets<=2.13.0,>=2.8.0->modelscope==1.9.5) (4.9.0)\n",
      "\n",
      "INFO: pip is looking at multiple versions of multiprocess to determine which version is compatible with other requirements. This could take a while.\n",
      "\n",
      "Collecting multiprocess (from datasets<=2.13.0,>=2.8.0->modelscope==1.9.5)\n",
      "\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/bc/f7/7ec7fddc92e50714ea3745631f79bd9c96424cb2702632521028e57d3a36/multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
      "\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m44.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\n",
      "\u001b[?25h  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/b8/0c/c26b346b41bb1f81ac921fa10074a9595c22e5f99cc89c0410fc4efd5df3/multiprocess-0.70.14-py310-none-any.whl (134 kB)\n",
      "\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.3/134.3 kB\u001b[0m \u001b[31m41.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\n",
      "\u001b[?25hRequirement already satisfied: cffi>=1.12 in /opt/conda/lib/python3.10/site-packages (from cryptography>=2.6.0->aliyun-python-sdk-core>=2.13.12->oss2->modelscope==1.9.5) (1.15.1)\n",
      "\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.10/site-packages (from cffi>=1.12->cryptography>=2.6.0->aliyun-python-sdk-core>=2.13.12->oss2->modelscope==1.9.5) (2.21)\n",
      "\n",
      "\u001b[33mDEPRECATION: pytorch-lightning 1.7.7 has a non-standard dependency specifier torch>=1.9.*. pip 24.1 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pytorch-lightning or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\n",
      "\u001b[0mInstalling collected packages: dill, multiprocess, datasets, modelscope\n",
      "\n",
      "  Attempting uninstall: dill\n",
      "\n",
      "    Found existing installation: dill 0.3.7\n",
      "\n",
      "    Uninstalling dill-0.3.7:\n",
      "\n",
      "      Successfully uninstalled dill-0.3.7\n",
      "\n",
      "  Attempting uninstall: multiprocess\n",
      "\n",
      "    Found existing installation: multiprocess 0.70.15\n",
      "\n",
      "    Uninstalling multiprocess-0.70.15:\n",
      "\n",
      "      Successfully uninstalled multiprocess-0.70.15\n",
      "\n",
      "  Attempting uninstall: datasets\n",
      "\n",
      "    Found existing installation: datasets 2.16.1\n",
      "\n",
      "    Uninstalling datasets-2.16.1:\n",
      "\n",
      "      Successfully uninstalled datasets-2.16.1\n",
      "\n",
      "  Attempting uninstall: modelscope\n",
      "\n",
      "    Found existing installation: modelscope 1.14.0\n",
      "\n",
      "    Uninstalling modelscope-1.14.0:\n",
      "\n",
      "      Successfully uninstalled modelscope-1.14.0\n",
      "\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "\n",
      "ms-swift 2.0.2 requires modelscope>=1.13.3, but you have modelscope 1.9.5 which is incompatible.\u001b[0m\u001b[31m\n",
      "\n",
      "\u001b[0mSuccessfully installed datasets-2.13.0 dill-0.3.6 modelscope-1.9.5 multiprocess-0.70.14\n",
      "\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1.2\u001b[0m\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\n",
      "Looking in indexes: https://mirrors.cloud.aliyuncs.com/pypi/simple\n",
      "\n",
      "Collecting transformers>=4.39.0\n",
      "\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/ad/ff/b3e311e58b9c90b149fb957953b228287d7c9fe78df9a3a72e8715c5fc56/transformers-4.43.3-py3-none-any.whl (9.4 MB)\n",
      "\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.4/9.4 MB\u001b[0m \u001b[31m66.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\n",
      "\u001b[?25hRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers>=4.39.0) (3.13.1)\n",
      "\n",
      "Collecting huggingface-hub<1.0,>=0.23.2 (from transformers>=4.39.0)\n",
      "\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/93/14/6a82b1c2eab5a828f7d3d675811660eb68424e8b039191f418a94e8d9726/huggingface_hub-0.24.2-py3-none-any.whl (417 kB)\n",
      "\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m417.2/417.2 kB\u001b[0m \u001b[31m94.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.39.0) (1.26.3)\n",
      "\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.39.0) (23.1)\n",
      "\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.39.0) (6.0.1)\n",
      "\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.39.0) (2023.12.25)\n",
      "\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers>=4.39.0) (2.31.0)\n",
      "\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.39.0) (0.4.1)\n",
      "\n",
      "Collecting tokenizers<0.20,>=0.19 (from transformers>=4.39.0)\n",
      "\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/40/4f/eb78de4af3b17b589f43a369cbf0c3a7173f25c3d2cd93068852c07689aa/tokenizers-0.19.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
      "\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m76.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\n",
      "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.39.0) (4.65.0)\n",
      "\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers>=4.39.0) (2023.10.0)\n",
      "\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers>=4.39.0) (4.9.0)\n",
      "\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers>=4.39.0) (2.0.4)\n",
      "\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers>=4.39.0) (3.4)\n",
      "\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers>=4.39.0) (1.26.16)\n",
      "\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers>=4.39.0) (2023.11.17)\n",
      "\n",
      "\u001b[33mDEPRECATION: pytorch-lightning 1.7.7 has a non-standard dependency specifier torch>=1.9.*. pip 24.1 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pytorch-lightning or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\n",
      "\u001b[0mInstalling collected packages: huggingface-hub, tokenizers, transformers\n",
      "\n",
      "  Attempting uninstall: huggingface-hub\n",
      "\n",
      "    Found existing installation: huggingface-hub 0.20.3\n",
      "\n",
      "    Uninstalling huggingface-hub-0.20.3:\n",
      "\n",
      "      Successfully uninstalled huggingface-hub-0.20.3\n",
      "\n",
      "  Attempting uninstall: tokenizers\n",
      "\n",
      "    Found existing installation: tokenizers 0.15.1\n",
      "\n",
      "    Uninstalling tokenizers-0.15.1:\n",
      "\n",
      "      Successfully uninstalled tokenizers-0.15.1\n",
      "\n",
      "  Attempting uninstall: transformers\n",
      "\n",
      "    Found existing installation: transformers 4.38.2\n",
      "\n",
      "    Uninstalling transformers-4.38.2:\n",
      "\n",
      "      Successfully uninstalled transformers-4.38.2\n",
      "\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "\n",
      "autoawq 0.2.4 requires transformers<=4.38.2,>=4.35.0, but you have transformers 4.43.3 which is incompatible.\n",
      "\n",
      "ms-swift 2.0.2 requires modelscope>=1.13.3, but you have modelscope 1.9.5 which is incompatible.\n",
      "\n",
      "ms-swift 2.0.2 requires transformers<4.41,>=4.33, but you have transformers 4.43.3 which is incompatible.\n",
      "\n",
      "optimum 1.19.1 requires transformers[sentencepiece]<4.41.0,>=4.26.0, but you have transformers 4.43.3 which is incompatible.\n",
      "\n",
      "pai-easycv 0.11.6 requires timm==0.5.4, but you have timm 0.9.16 which is incompatible.\u001b[0m\u001b[31m\n",
      "\n",
      "\u001b[0mSuccessfully installed huggingface-hub-0.24.2 tokenizers-0.19.1 transformers-4.43.3\n",
      "\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1.2\u001b[0m\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\n",
      "Looking in indexes: https://mirrors.cloud.aliyuncs.com/pypi/simple\n",
      "\n",
      "Collecting streamlit==1.24.0\n",
      "\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/3d/5f/1716c66c58a8b080f9673e7ca569044b1b8ac6a5cd8519fe4b1afa89abf8/streamlit-1.24.0-py2.py3-none-any.whl (8.9 MB)\n",
      "\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.9/8.9 MB\u001b[0m \u001b[31m64.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\n",
      "\u001b[?25hCollecting altair<6,>=4.0 (from streamlit==1.24.0)\n",
      "\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/46/30/2118537233fa72c1d91a81f5908a7e843a6601ccc68b76838ebc4951505f/altair-5.3.0-py3-none-any.whl (857 kB)\n",
      "\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m857.8/857.8 kB\u001b[0m \u001b[31m131.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\n",
      "\u001b[?25hCollecting blinker<2,>=1.0.0 (from streamlit==1.24.0)\n",
      "\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/bb/2a/10164ed1f31196a2f7f3799368a821765c62851ead0e630ab52b8e14b4d0/blinker-1.8.2-py3-none-any.whl (9.5 kB)\n",
      "\n",
      "Requirement already satisfied: cachetools<6,>=4.0 in /opt/conda/lib/python3.10/site-packages (from streamlit==1.24.0) (5.3.2)\n",
      "\n",
      "Requirement already satisfied: click<9,>=7.0 in /opt/conda/lib/python3.10/site-packages (from streamlit==1.24.0) (8.1.7)\n",
      "\n",
      "Collecting importlib-metadata<7,>=1.4 (from streamlit==1.24.0)\n",
      "\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/59/9b/ecce94952ab5ea74c31dcf9ccf78ccd484eebebef06019bf8cb579ab4519/importlib_metadata-6.11.0-py3-none-any.whl (23 kB)\n",
      "\n",
      "Requirement already satisfied: numpy<2,>=1 in /opt/conda/lib/python3.10/site-packages (from streamlit==1.24.0) (1.26.3)\n",
      "\n",
      "Requirement already satisfied: packaging<24,>=14.1 in /opt/conda/lib/python3.10/site-packages (from streamlit==1.24.0) (23.1)\n",
      "\n",
      "Requirement already satisfied: pandas<3,>=0.25 in /opt/conda/lib/python3.10/site-packages (from streamlit==1.24.0) (2.2.0)\n",
      "\n",
      "Collecting pillow<10,>=6.2.0 (from streamlit==1.24.0)\n",
      "\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/25/6b/d3c35d207c9c0b6c2f855420f62e64ef43d348e8c797ad1c32b9f2106a19/Pillow-9.5.0-cp310-cp310-manylinux_2_28_x86_64.whl (3.4 MB)\n",
      "\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m85.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\n",
      "\u001b[?25hRequirement already satisfied: protobuf<5,>=3.20 in /opt/conda/lib/python3.10/site-packages (from streamlit==1.24.0) (3.20.3)\n",
      "\n",
      "Requirement already satisfied: pyarrow>=4.0 in /opt/conda/lib/python3.10/site-packages (from streamlit==1.24.0) (15.0.0)\n",
      "\n",
      "Collecting pympler<2,>=0.9 (from streamlit==1.24.0)\n",
      "\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/79/4f/a6a2e2b202d7fd97eadfe90979845b8706676b41cbd3b42ba75adf329d1f/Pympler-1.1-py3-none-any.whl (165 kB)\n",
      "\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m165.8/165.8 kB\u001b[0m \u001b[31m46.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil<3,>=2 in /opt/conda/lib/python3.10/site-packages (from streamlit==1.24.0) (2.8.2)\n",
      "\n",
      "Requirement already satisfied: requests<3,>=2.4 in /opt/conda/lib/python3.10/site-packages (from streamlit==1.24.0) (2.31.0)\n",
      "\n",
      "Requirement already satisfied: rich<14,>=10.11.0 in /opt/conda/lib/python3.10/site-packages (from streamlit==1.24.0) (13.7.1)\n",
      "\n",
      "Requirement already satisfied: tenacity<9,>=8.0.0 in /opt/conda/lib/python3.10/site-packages (from streamlit==1.24.0) (8.2.3)\n",
      "\n",
      "Requirement already satisfied: toml<2 in /opt/conda/lib/python3.10/site-packages (from streamlit==1.24.0) (0.10.2)\n",
      "\n",
      "Requirement already satisfied: typing-extensions<5,>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from streamlit==1.24.0) (4.9.0)\n",
      "\n",
      "Collecting tzlocal<5,>=1.1 (from streamlit==1.24.0)\n",
      "\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/55/a6/a75af44665e5e77e52f6789eef4f8bc056c8e039d96c804b975806942580/tzlocal-4.3.1-py3-none-any.whl (20 kB)\n",
      "\n",
      "Collecting validators<1,>=0.2 (from streamlit==1.24.0)\n",
      "\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/04/22/91b4bd36df27e651daedd93d03d5d3bb6029fdb0b55494e45ee46c36c570/validators-0.33.0-py3-none-any.whl (43 kB)\n",
      "\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.3/43.3 kB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\n",
      "\u001b[?25hCollecting gitpython!=3.1.19,<4,>=3 (from streamlit==1.24.0)\n",
      "\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/e9/bd/cc3a402a6439c15c3d4294333e13042b915bbeab54edc457c723931fed3f/GitPython-3.1.43-py3-none-any.whl (207 kB)\n",
      "\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m65.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\n",
      "\u001b[?25hCollecting pydeck<1,>=0.1.dev5 (from streamlit==1.24.0)\n",
      "\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/ab/4c/b888e6cf58bd9db9c93f40d1c6be8283ff49d88919231afe93a6bcf61626/pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
      "\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m119.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\n",
      "\u001b[?25hRequirement already satisfied: tornado<7,>=6.0.3 in /opt/conda/lib/python3.10/site-packages (from streamlit==1.24.0) (6.4)\n",
      "\n",
      "Collecting watchdog (from streamlit==1.24.0)\n",
      "\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/24/01/a4034a94a5f1828eb050230e7cf13af3ac23cf763512b6afe008d3def97c/watchdog-4.0.1-py3-none-manylinux2014_x86_64.whl (83 kB)\n",
      "\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.0/83.0 kB\u001b[0m \u001b[31m30.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\n",
      "\u001b[?25hRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from altair<6,>=4.0->streamlit==1.24.0) (3.1.2)\n",
      "\n",
      "Requirement already satisfied: jsonschema>=3.0 in /opt/conda/lib/python3.10/site-packages (from altair<6,>=4.0->streamlit==1.24.0) (4.21.1)\n",
      "\n",
      "Collecting toolz (from altair<6,>=4.0->streamlit==1.24.0)\n",
      "\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/b7/8a/d82202c9f89eab30f9fc05380daae87d617e2ad11571ab23d7c13a29bb54/toolz-0.12.1-py3-none-any.whl (56 kB)\n",
      "\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.1/56.1 kB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\n",
      "\u001b[?25hCollecting gitdb<5,>=4.0.1 (from gitpython!=3.1.19,<4,>=3->streamlit==1.24.0)\n",
      "\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/fd/5b/8f0c4a5bb9fd491c277c21eff7ccae71b47d43c4446c9d0c6cff2fe8c2c4/gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
      "\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m23.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\n",
      "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.10/site-packages (from importlib-metadata<7,>=1.4->streamlit==1.24.0) (3.17.0)\n",
      "\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas<3,>=0.25->streamlit==1.24.0) (2023.4)\n",
      "\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas<3,>=0.25->streamlit==1.24.0) (2023.4)\n",
      "\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil<3,>=2->streamlit==1.24.0) (1.16.0)\n",
      "\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.4->streamlit==1.24.0) (2.0.4)\n",
      "\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.4->streamlit==1.24.0) (3.4)\n",
      "\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.4->streamlit==1.24.0) (1.26.16)\n",
      "\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.4->streamlit==1.24.0) (2023.11.17)\n",
      "\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich<14,>=10.11.0->streamlit==1.24.0) (3.0.0)\n",
      "\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich<14,>=10.11.0->streamlit==1.24.0) (2.17.2)\n",
      "\n",
      "Collecting pytz-deprecation-shim (from tzlocal<5,>=1.1->streamlit==1.24.0)\n",
      "\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/eb/73/3eaab547ca809754e67e06871cff0fc962bafd4b604e15f31896a0f94431/pytz_deprecation_shim-0.1.0.post0-py2.py3-none-any.whl (15 kB)\n",
      "\n",
      "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3->streamlit==1.24.0)\n",
      "\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/a7/a5/10f97f73544edcdef54409f1d839f6049a0d79df68adbc1ceb24d1aaca42/smmap-5.0.1-py3-none-any.whl (24 kB)\n",
      "\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->altair<6,>=4.0->streamlit==1.24.0) (2.1.3)\n",
      "\n",
      "Requirement already satisfied: attrs>=22.2.0 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit==1.24.0) (23.2.0)\n",
      "\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit==1.24.0) (2023.12.1)\n",
      "\n",
      "Requirement already satisfied: referencing>=0.28.4 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit==1.24.0) (0.33.0)\n",
      "\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit==1.24.0) (0.17.1)\n",
      "\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich<14,>=10.11.0->streamlit==1.24.0) (0.1.2)\n",
      "\n",
      "\u001b[33mDEPRECATION: pytorch-lightning 1.7.7 has a non-standard dependency specifier torch>=1.9.*. pip 24.1 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pytorch-lightning or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\n",
      "\u001b[0mInstalling collected packages: watchdog, validators, toolz, smmap, pytz-deprecation-shim, pympler, pillow, importlib-metadata, blinker, tzlocal, pydeck, gitdb, gitpython, altair, streamlit\n",
      "\n",
      "  Attempting uninstall: pillow\n",
      "\n",
      "    Found existing installation: pillow 10.2.0\n",
      "\n",
      "    Uninstalling pillow-10.2.0:\n",
      "\n",
      "      Successfully uninstalled pillow-10.2.0\n",
      "\n",
      "  Attempting uninstall: importlib-metadata\n",
      "\n",
      "    Found existing installation: importlib-metadata 7.0.1\n",
      "\n",
      "    Uninstalling importlib-metadata-7.0.1:\n",
      "\n",
      "      Successfully uninstalled importlib-metadata-7.0.1\n",
      "\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "\n",
      "basicsr 1.4.2 requires tb-nightly, which is not installed.\n",
      "\n",
      "ms-swift 2.0.2 requires modelscope>=1.13.3, but you have modelscope 1.9.5 which is incompatible.\n",
      "\n",
      "ms-swift 2.0.2 requires transformers<4.41,>=4.33, but you have transformers 4.43.3 which is incompatible.\n",
      "\n",
      "pai-easycv 0.11.6 requires timm==0.5.4, but you have timm 0.9.16 which is incompatible.\u001b[0m\u001b[31m\n",
      "\n",
      "\u001b[0mSuccessfully installed altair-5.3.0 blinker-1.8.2 gitdb-4.0.11 gitpython-3.1.43 importlib-metadata-6.11.0 pillow-9.5.0 pydeck-0.9.1 pympler-1.1 pytz-deprecation-shim-0.1.0.post0 smmap-5.0.1 streamlit-1.24.0 toolz-0.12.1 tzlocal-4.3.1 validators-0.33.0 watchdog-4.0.1\n",
      "\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1.2\u001b[0m\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\n",
      "Looking in indexes: https://mirrors.cloud.aliyuncs.com/pypi/simple\n",
      "\n",
      "Requirement already satisfied: sentencepiece==0.1.99 in /opt/conda/lib/python3.10/site-packages (0.1.99)\n",
      "\n",
      "\u001b[33mDEPRECATION: pytorch-lightning 1.7.7 has a non-standard dependency specifier torch>=1.9.*. pip 24.1 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pytorch-lightning or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1.2\u001b[0m\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\n",
      "Looking in indexes: https://mirrors.cloud.aliyuncs.com/pypi/simple\n",
      "\n",
      "Requirement already satisfied: transformers_stream_generator==0.0.4 in /opt/conda/lib/python3.10/site-packages (0.0.4)\n",
      "\n",
      "Requirement already satisfied: transformers>=4.26.1 in /opt/conda/lib/python3.10/site-packages (from transformers_stream_generator==0.0.4) (4.43.3)\n",
      "\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers>=4.26.1->transformers_stream_generator==0.0.4) (3.13.1)\n",
      "\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.26.1->transformers_stream_generator==0.0.4) (0.24.2)\n",
      "\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.26.1->transformers_stream_generator==0.0.4) (1.26.3)\n",
      "\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.26.1->transformers_stream_generator==0.0.4) (23.1)\n",
      "\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.26.1->transformers_stream_generator==0.0.4) (6.0.1)\n",
      "\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.26.1->transformers_stream_generator==0.0.4) (2023.12.25)\n",
      "\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers>=4.26.1->transformers_stream_generator==0.0.4) (2.31.0)\n",
      "\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.26.1->transformers_stream_generator==0.0.4) (0.4.1)\n",
      "\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.26.1->transformers_stream_generator==0.0.4) (0.19.1)\n",
      "\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.26.1->transformers_stream_generator==0.0.4) (4.65.0)\n",
      "\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers>=4.26.1->transformers_stream_generator==0.0.4) (2023.10.0)\n",
      "\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers>=4.26.1->transformers_stream_generator==0.0.4) (4.9.0)\n",
      "\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers>=4.26.1->transformers_stream_generator==0.0.4) (2.0.4)\n",
      "\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers>=4.26.1->transformers_stream_generator==0.0.4) (3.4)\n",
      "\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers>=4.26.1->transformers_stream_generator==0.0.4) (1.26.16)\n",
      "\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers>=4.26.1->transformers_stream_generator==0.0.4) (2023.11.17)\n",
      "\n",
      "\u001b[33mDEPRECATION: pytorch-lightning 1.7.7 has a non-standard dependency specifier torch>=1.9.*. pip 24.1 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pytorch-lightning or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1.2\u001b[0m\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\n",
      "Looking in indexes: https://mirrors.cloud.aliyuncs.com/pypi/simple\n",
      "\n",
      "Collecting datasets==2.18.0\n",
      "\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/95/fc/661a7f06e8b7d48fcbd3f55423b7ff1ac3ce59526f146fda87a1e1788ee4/datasets-2.18.0-py3-none-any.whl (510 kB)\n",
      "\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m510.5/510.5 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\n",
      "\u001b[?25hRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from datasets==2.18.0) (3.13.1)\n",
      "\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from datasets==2.18.0) (1.26.3)\n",
      "\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets==2.18.0) (15.0.0)\n",
      "\n",
      "Requirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.10/site-packages (from datasets==2.18.0) (0.6)\n",
      "\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets==2.18.0) (0.3.6)\n",
      "\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets==2.18.0) (2.2.0)\n",
      "\n",
      "Requirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from datasets==2.18.0) (2.31.0)\n",
      "\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from datasets==2.18.0) (4.65.0)\n",
      "\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets==2.18.0) (3.4.1)\n",
      "\n",
      "Requirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets==2.18.0) (0.70.14)\n",
      "\n",
      "Requirement already satisfied: fsspec<=2024.2.0,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2024.2.0,>=2023.1.0->datasets==2.18.0) (2023.10.0)\n",
      "\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets==2.18.0) (3.9.3)\n",
      "\n",
      "Requirement already satisfied: huggingface-hub>=0.19.4 in /opt/conda/lib/python3.10/site-packages (from datasets==2.18.0) (0.24.2)\n",
      "\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets==2.18.0) (23.1)\n",
      "\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets==2.18.0) (6.0.1)\n",
      "\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.18.0) (1.3.1)\n",
      "\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.18.0) (23.2.0)\n",
      "\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.18.0) (1.4.1)\n",
      "\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.18.0) (6.0.4)\n",
      "\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.18.0) (1.9.4)\n",
      "\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.18.0) (4.0.3)\n",
      "\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.19.4->datasets==2.18.0) (4.9.0)\n",
      "\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets==2.18.0) (2.0.4)\n",
      "\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets==2.18.0) (3.4)\n",
      "\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets==2.18.0) (1.26.16)\n",
      "\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets==2.18.0) (2023.11.17)\n",
      "\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets==2.18.0) (2.8.2)\n",
      "\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets==2.18.0) (2023.4)\n",
      "\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets==2.18.0) (2023.4)\n",
      "\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets==2.18.0) (1.16.0)\n",
      "\n",
      "\u001b[33mDEPRECATION: pytorch-lightning 1.7.7 has a non-standard dependency specifier torch>=1.9.*. pip 24.1 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pytorch-lightning or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\n",
      "\u001b[0mInstalling collected packages: datasets\n",
      "\n",
      "  Attempting uninstall: datasets\n",
      "\n",
      "    Found existing installation: datasets 2.13.0\n",
      "\n",
      "    Uninstalling datasets-2.13.0:\n",
      "\n",
      "      Successfully uninstalled datasets-2.13.0\n",
      "\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "\n",
      "autoawq 0.2.4 requires transformers<=4.38.2,>=4.35.0, but you have transformers 4.43.3 which is incompatible.\n",
      "\n",
      "modelscope 1.9.5 requires datasets<=2.13.0,>=2.8.0, but you have datasets 2.18.0 which is incompatible.\n",
      "\n",
      "ms-swift 2.0.2 requires modelscope>=1.13.3, but you have modelscope 1.9.5 which is incompatible.\n",
      "\n",
      "ms-swift 2.0.2 requires transformers<4.41,>=4.33, but you have transformers 4.43.3 which is incompatible.\n",
      "\n",
      "optimum 1.19.1 requires transformers[sentencepiece]<4.41.0,>=4.26.0, but you have transformers 4.43.3 which is incompatible.\u001b[0m\u001b[31m\n",
      "\n",
      "\u001b[0mSuccessfully installed datasets-2.18.0\n",
      "\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1.2\u001b[0m\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\n",
      "Looking in indexes: https://mirrors.cloud.aliyuncs.com/pypi/simple\n",
      "\n",
      "Requirement already satisfied: peft==0.10.0 in /opt/conda/lib/python3.10/site-packages (0.10.0)\n",
      "\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from peft==0.10.0) (1.26.3)\n",
      "\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from peft==0.10.0) (23.1)\n",
      "\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from peft==0.10.0) (5.9.7)\n",
      "\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from peft==0.10.0) (6.0.1)\n",
      "\n",
      "Requirement already satisfied: torch>=1.13.0 in /opt/conda/lib/python3.10/site-packages (from peft==0.10.0) (2.1.2+cu121)\n",
      "\n",
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (from peft==0.10.0) (4.43.3)\n",
      "\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from peft==0.10.0) (4.65.0)\n",
      "\n",
      "Requirement already satisfied: accelerate>=0.21.0 in /opt/conda/lib/python3.10/site-packages (from peft==0.10.0) (0.26.1)\n",
      "\n",
      "Requirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from peft==0.10.0) (0.4.1)\n",
      "\n",
      "Requirement already satisfied: huggingface-hub>=0.17.0 in /opt/conda/lib/python3.10/site-packages (from peft==0.10.0) (0.24.2)\n",
      "\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft==0.10.0) (3.13.1)\n",
      "\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft==0.10.0) (2023.10.0)\n",
      "\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft==0.10.0) (2.31.0)\n",
      "\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft==0.10.0) (4.9.0)\n",
      "\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.10.0) (1.12)\n",
      "\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.10.0) (3.2.1)\n",
      "\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.10.0) (3.1.2)\n",
      "\n",
      "Requirement already satisfied: triton==2.1.0 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.10.0) (2.1.0)\n",
      "\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers->peft==0.10.0) (2023.12.25)\n",
      "\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.10/site-packages (from transformers->peft==0.10.0) (0.19.1)\n",
      "\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.13.0->peft==0.10.0) (2.1.3)\n",
      "\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft==0.10.0) (2.0.4)\n",
      "\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft==0.10.0) (3.4)\n",
      "\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft==0.10.0) (1.26.16)\n",
      "\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft==0.10.0) (2023.11.17)\n",
      "\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.13.0->peft==0.10.0) (1.3.0)\n",
      "\n",
      "\u001b[33mDEPRECATION: pytorch-lightning 1.7.7 has a non-standard dependency specifier torch>=1.9.*. pip 24.1 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pytorch-lightning or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1.2\u001b[0m\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\n",
      "Looking in indexes: https://mirrors.cloud.aliyuncs.com/pypi/simple\n",
      "\n",
      "Requirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (0.26.1)\n",
      "\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from accelerate) (1.26.3)\n",
      "\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (23.1)\n",
      "\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate) (5.9.7)\n",
      "\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from accelerate) (6.0.1)\n",
      "\n",
      "Requirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (2.1.2+cu121)\n",
      "\n",
      "Requirement already satisfied: huggingface-hub in /opt/conda/lib/python3.10/site-packages (from accelerate) (0.24.2)\n",
      "\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from accelerate) (0.4.1)\n",
      "\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.13.1)\n",
      "\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (4.9.0)\n",
      "\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (1.12)\n",
      "\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.2.1)\n",
      "\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.1.2)\n",
      "\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (2023.10.0)\n",
      "\n",
      "Requirement already satisfied: triton==2.1.0 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (2.1.0)\n",
      "\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->accelerate) (2.31.0)\n",
      "\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->accelerate) (4.65.0)\n",
      "\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\n",
      "\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (2.0.4)\n",
      "\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (3.4)\n",
      "\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (1.26.16)\n",
      "\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (2023.11.17)\n",
      "\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
      "\n",
      "\u001b[33mDEPRECATION: pytorch-lightning 1.7.7 has a non-standard dependency specifier torch>=1.9.*. pip 24.1 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pytorch-lightning or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1.2\u001b[0m\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\n",
      "Looking in indexes: https://mirrors.cloud.aliyuncs.com/pypi/simple\n",
      "\n",
      "Collecting tf-keras\n",
      "\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/21/8b/75f7572ec0273ed8da50bc19defe08aaaafcc15fda3407db53f49acec814/tf_keras-2.17.0-py3-none-any.whl (1.7 MB)\n",
      "\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\n",
      "\u001b[?25hCollecting tensorflow<2.18,>=2.17 (from tf-keras)\n",
      "\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/ad/fc/b1b67cbad080b8b7a13d0118e2cc60a28dbdbacabdc3f8dd0480210c3f25/tensorflow-2.17.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (601.3 MB)\n",
      "\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m601.3/601.3 MB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\n",
      "\u001b[?25hRequirement already satisfied: absl-py>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.18,>=2.17->tf-keras) (2.0.0)\n",
      "\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.18,>=2.17->tf-keras) (1.6.3)\n",
      "\n",
      "Collecting flatbuffers>=24.3.25 (from tensorflow<2.18,>=2.17->tf-keras)\n",
      "\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/41/f0/7e988a019bc54b2dbd0ad4182ef2d53488bb02e58694cd79d61369e85900/flatbuffers-24.3.25-py2.py3-none-any.whl (26 kB)\n",
      "\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.18,>=2.17->tf-keras) (0.5.4)\n",
      "\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.18,>=2.17->tf-keras) (0.2.0)\n",
      "\n",
      "Requirement already satisfied: h5py>=3.10.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.18,>=2.17->tf-keras) (3.10.0)\n",
      "\n",
      "Requirement already satisfied: libclang>=13.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.18,>=2.17->tf-keras) (16.0.6)\n",
      "\n",
      "Collecting ml-dtypes<0.5.0,>=0.3.1 (from tensorflow<2.18,>=2.17->tf-keras)\n",
      "\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/9d/15/e5af59287e712b26ce776f00911c45c97ac9f4cd82d46500602cc94127ed/ml_dtypes-0.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
      "\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m70.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\n",
      "\u001b[?25hRequirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.18,>=2.17->tf-keras) (3.3.0)\n",
      "\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.18,>=2.17->tf-keras) (23.1)\n",
      "\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.18,>=2.17->tf-keras) (3.20.3)\n",
      "\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.18,>=2.17->tf-keras) (2.31.0)\n",
      "\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.18,>=2.17->tf-keras) (68.0.0)\n",
      "\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.18,>=2.17->tf-keras) (1.16.0)\n",
      "\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.18,>=2.17->tf-keras) (2.4.0)\n",
      "\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.18,>=2.17->tf-keras) (4.9.0)\n",
      "\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.18,>=2.17->tf-keras) (1.14.1)\n",
      "\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.18,>=2.17->tf-keras) (1.60.0)\n",
      "\n",
      "Collecting tensorboard<2.18,>=2.17 (from tensorflow<2.18,>=2.17->tf-keras)\n",
      "\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/0a/32/2e8545fb0592f33e3aca5951e8b01008b76d61b440658cbdc37b4eaebf0b/tensorboard-2.17.0-py3-none-any.whl (5.5 MB)\n",
      "\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m146.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\n",
      "\u001b[?25hCollecting keras>=3.2.0 (from tensorflow<2.18,>=2.17->tf-keras)\n",
      "\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/46/43/03fa53f027e78af4a6bee3564d05cb34d9f5b924dc69c85f8ef5cb950ff1/keras-3.4.1-py3-none-any.whl (1.1 MB)\n",
      "\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m122.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\n",
      "\u001b[?25hRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.18,>=2.17->tf-keras) (0.35.0)\n",
      "\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.18,>=2.17->tf-keras) (1.26.3)\n",
      "\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow<2.18,>=2.17->tf-keras) (0.41.2)\n",
      "\n",
      "Requirement already satisfied: rich in /opt/conda/lib/python3.10/site-packages (from keras>=3.2.0->tensorflow<2.18,>=2.17->tf-keras) (13.7.1)\n",
      "\n",
      "Collecting namex (from keras>=3.2.0->tensorflow<2.18,>=2.17->tf-keras)\n",
      "\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/73/59/7854fbfb59f8ae35483ce93493708be5942ebb6328cd85b3a609df629736/namex-0.0.8-py3-none-any.whl (5.8 kB)\n",
      "\n",
      "Collecting optree (from keras>=3.2.0->tensorflow<2.18,>=2.17->tf-keras)\n",
      "\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/02/ab/743dc0e9d75c8a81239c74d8d390bc593dc3aa3017162cc5fb58b1304674/optree-0.12.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (347 kB)\n",
      "\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m347.7/347.7 kB\u001b[0m \u001b[31m86.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\n",
      "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow<2.18,>=2.17->tf-keras) (2.0.4)\n",
      "\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow<2.18,>=2.17->tf-keras) (3.4)\n",
      "\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow<2.18,>=2.17->tf-keras) (1.26.16)\n",
      "\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow<2.18,>=2.17->tf-keras) (2023.11.17)\n",
      "\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.18,>=2.17->tensorflow<2.18,>=2.17->tf-keras) (3.5.1)\n",
      "\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.18,>=2.17->tensorflow<2.18,>=2.17->tf-keras) (0.7.2)\n",
      "\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.18,>=2.17->tensorflow<2.18,>=2.17->tf-keras) (3.0.1)\n",
      "\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow<2.18,>=2.17->tf-keras) (2.1.3)\n",
      "\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich->keras>=3.2.0->tensorflow<2.18,>=2.17->tf-keras) (3.0.0)\n",
      "\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich->keras>=3.2.0->tensorflow<2.18,>=2.17->tf-keras) (2.17.2)\n",
      "\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow<2.18,>=2.17->tf-keras) (0.1.2)\n",
      "\n",
      "\u001b[33mDEPRECATION: pytorch-lightning 1.7.7 has a non-standard dependency specifier torch>=1.9.*. pip 24.1 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pytorch-lightning or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\n",
      "\u001b[0mInstalling collected packages: namex, flatbuffers, optree, ml-dtypes, tensorboard, keras, tensorflow, tf-keras\n",
      "\n",
      "  Attempting uninstall: flatbuffers\n",
      "\n",
      "    Found existing installation: flatbuffers 23.5.26\n",
      "\n",
      "    Uninstalling flatbuffers-23.5.26:\n",
      "\n",
      "      Successfully uninstalled flatbuffers-23.5.26\n",
      "\n",
      "  Attempting uninstall: ml-dtypes\n",
      "\n",
      "    Found existing installation: ml-dtypes 0.2.0\n",
      "\n",
      "    Uninstalling ml-dtypes-0.2.0:\n",
      "\n",
      "      Successfully uninstalled ml-dtypes-0.2.0\n",
      "\n",
      "  Attempting uninstall: tensorboard\n",
      "\n",
      "    Found existing installation: tensorboard 2.16.2\n",
      "\n",
      "    Uninstalling tensorboard-2.16.2:\n",
      "\n",
      "      Successfully uninstalled tensorboard-2.16.2\n",
      "\n",
      "  Attempting uninstall: keras\n",
      "\n",
      "    Found existing installation: keras 2.14.0\n",
      "\n",
      "    Uninstalling keras-2.14.0:\n",
      "\n",
      "      Successfully uninstalled keras-2.14.0\n",
      "\n",
      "  Attempting uninstall: tensorflow\n",
      "\n",
      "    Found existing installation: tensorflow 2.14.0\n",
      "\n",
      "    Uninstalling tensorflow-2.14.0:\n",
      "\n",
      "      Successfully uninstalled tensorflow-2.14.0\n",
      "\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "\n",
      "ms-swift 2.0.2 requires modelscope>=1.13.3, but you have modelscope 1.9.5 which is incompatible.\n",
      "\n",
      "ms-swift 2.0.2 requires transformers<4.41,>=4.33, but you have transformers 4.43.3 which is incompatible.\n",
      "\n",
      "pai-easycv 0.11.6 requires timm==0.5.4, but you have timm 0.9.16 which is incompatible.\u001b[0m\u001b[31m\n",
      "\n",
      "\u001b[0mSuccessfully installed flatbuffers-24.3.25 keras-3.4.1 ml-dtypes-0.4.0 namex-0.0.8 optree-0.12.1 tensorboard-2.17.0 tensorflow-2.17.0 tf-keras-2.17.0\n",
      "\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1.2\u001b[0m\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install modelscope==1.9.5\n",
    "!pip install \"transformers>=4.39.0\"\n",
    "!pip install streamlit==1.24.0\n",
    "!pip install sentencepiece==0.1.99\n",
    "!pip install transformers_stream_generator==0.0.4\n",
    "!pip install datasets==2.18.0\n",
    "!pip install peft==0.10.0\n",
    "!pip install openai==1.17.1\n",
    "!pip install tqdm==4.64.1\n",
    "!pip install transformers==4.39.3\n",
    "!python -m pip install setuptools==69.5.1\n",
    "!pip install vllm==0.4.0.post1\n",
    "!pip install nest-asyncio\n",
    "!pip install accelerate\n",
    "!pip install tf-keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c111418c-1568-4ae4-8813-61c70865945e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from modelscope import snapshot_download, AutoModel, AutoTokenizer\n",
    "import os\n",
    "model_dir = snapshot_download('qwen/Qwen2-7B-Instruct', cache_dir='./', revision='master')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "071ffac7-9617-4ad8-8df1-52a7b96576cf",
   "metadata": {},
   "source": [
    "## 这里运行完请重启notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8102f503-40ce-4132-b901-a2fcf8079f8c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-27T15:24:29.787218Z",
     "iopub.status.busy": "2024-07-27T15:24:29.787026Z",
     "iopub.status.idle": "2024-07-27T15:24:36.288346Z",
     "shell.execute_reply": "2024-07-27T15:24:36.287876Z",
     "shell.execute_reply.started": "2024-07-27T15:24:29.787198Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "\n",
      "2024-07-27 23:24:31.930897: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "\n",
      "2024-07-27 23:24:31.942602: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "\n",
      "2024-07-27 23:24:31.956712: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "\n",
      "2024-07-27 23:24:31.960944: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "\n",
      "2024-07-27 23:24:31.971152: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\n",
      "2024-07-27 23:24:32.625560: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, DataCollatorForSeq2Seq, TrainingArguments, Trainer, GenerationConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b226948-17c5-4aa4-8a81-06b61e93c425",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-27T15:24:55.871707Z",
     "iopub.status.busy": "2024-07-27T15:24:55.871404Z",
     "iopub.status.idle": "2024-07-27T15:24:55.920013Z",
     "shell.execute_reply": "2024-07-27T15:24:55.919573Z",
     "shell.execute_reply.started": "2024-07-27T15:24:55.871689Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 将JSON文件转换为CSV文件\n",
    "df = pd.read_json('ana.json')\n",
    "ds = Dataset.from_pandas(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e7253ad6-95e1-48c5-8e24-5a90adc112fc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-27T15:24:58.501761Z",
     "iopub.status.busy": "2024-07-27T15:24:58.501451Z",
     "iopub.status.idle": "2024-07-27T15:24:58.510477Z",
     "shell.execute_reply": "2024-07-27T15:24:58.510039Z",
     "shell.execute_reply.started": "2024-07-27T15:24:58.501743Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'instruction': ['你是一个逻辑推理专家，擅长解决逻辑推理问题。以下是一个逻辑推理的题目，形式为单项选择题。所有的问题都是（close-world assumption）闭世界假设，即未观测事实都为假。请逐步分析问题并在最后一行输出答案，最后一行的格式为\"答案是：A\"。题目如下：\\n\\n### 题目:\\n假设您需要构建一个二叉搜索树，其中每个节点或者是一个空的节点（称为\"空节点\"），或者是一个包含一个整数值和两个子树的节点（称为\"数值节点\"）。以下是构建这棵树的规则：\\n\\n1. 树中不存在重复的元素。\\n2. 对于每个数值节点，其左子树的所有值都小于该节点的值，其右子树的所有值都大于该节点的值。\\n3. 插入一个新值到一个\"空节点\"时，该\"空节点\"会被一个包含新值的新的数值节点取代。\\n4. 插入一个已存在的数值将不会改变树。\\n\\n请基于以上规则，回答以下选择题：\\n\\n### 问题:\\n选择题 1：\\n给定一个空的二叉搜索树，插入下列数字: [5, 9, 2, 10, 11, 3]，下面哪个选项正确描述了结果树的结构？\\nA. tree(5, tree(2, tree(3, nil, nil), nil), tree(9, tree(10, nil, nil), tree(11, nil, nil)))\\nB. tree(5, tree(2, nil, tree(3, nil, nil)), tree(9, nil, tree(10, nil, tree(11, nil, nil))))\\nC. tree(5, tree(3, tree(2, nil, nil), nil), tree(9, nil, tree(10, tree(11, nil, nil), nil)))\\nD. tree(5, nil, tree(2, nil, tree(3, nil, nil)), tree(9, tree(11, nil, nil), tree(10, nil, nil)))\\n',\n",
       "  '你是一个逻辑推理专家，擅长解决逻辑推理问题。以下是一个逻辑推理的题目，形式为单项选择题。所有的问题都是（close-world assumption）闭世界假设，即未观测事实都为假。请逐步分析问题并在最后一行输出答案，最后一行的格式为\"答案是：A\"。题目如下：\\n\\n### 题目:\\n**单项选择测试题**\\n\\n有一个函数可以从给定的列表中删除所有奇数，保留所有偶数。以下是该函数的逻辑描述：\\n\\n1. 如果列表为空，则返回空列表。\\n2. 对于列表中的每一个元素，如果该元素是奇数，则将其删除，继续处理列表中的下一个元素。\\n3. 如果该元素是偶数，则将其保留在结果列表中，并继续处理列表中的下一个元素。\\n\\n根据以上逻辑，回答以下选择题：\\n\\n### 问题:\\n选择题 3：\\n对于输入列表 [3,7,5,9]，函数返回的结果是什么？\\nA. [3, 7, 5, 9]\\nB. [0]\\nC. [7]\\nD. []\\n',\n",
       "  '你是一个逻辑推理专家，擅长解决逻辑推理问题。以下是一个逻辑推理的题目，形式为单项选择题。所有的问题都是（close-world assumption）闭世界假设，即未观测事实都为假。请逐步分析问题并在最后一行输出答案，最后一行的格式为\"答案是：A\"。题目如下：\\n\\n### 题目:\\n有一个函数用来计算斐波那契数列中的第N个数字。斐波那契数列定义如下：第0个数字是1，第1个数字也是1，从第2个数字开始，每个数字是其前两个数字之和。具体如下：\\n\\n1. 斐波那契数列的第0个数字是1。\\n2. 斐波那契数列的第1个数字是1。\\n3. 对于大于1的任何正整数N，第N个数字是第N-1个数字和第N-2个数字之和。\\n\\n根据上述定义，回答以下选择题：\\n\\n### 问题:\\n选择题 2：\\n斐波那契数列中的第4个数字是1吗？\\nA. 是\\nB. 不是\\n'],\n",
       " 'input': ['', '', ''],\n",
       " 'output': ['根据题目中的规则，我们依次插入数字 [5, 9, 2, 10, 11, 3] 来构建二叉搜索树。\\n\\n首先插入数字 5，树为：\\n```\\ntree(5, nil, nil)\\n```\\n\\n然后插入数字 9，由于 9 > 5，因此插入到右子树：\\n```\\ntree(5, nil, tree(9, nil, nil))\\n```\\n\\n接下来插入数字 2，由于 2 < 5，因此插入到左子树：\\n```\\ntree(5, tree(2, nil, nil), tree(9, nil, nil))\\n```\\n\\n再插入数字 10，由于 10 > 5 并且 10 > 9，所以插入到 9 的右子树：\\n```\\ntree(5, tree(2, nil, nil), tree(9, nil, tree(10, nil, nil)))\\n```\\n\\n继续插入数字 11，由于 11 > 5 并且 11 > 9 和 11 > 10，所以插入到 10 的右子树：\\n```\\ntree(5, tree(2, nil, nil), tree(9, nil, tree(10, nil, tree(11, nil, nil))))\\n```\\n\\n最后插入数字 3，由于 3 < 5 但是 3 > 2，所以插入到 2 的右子树：\\n```\\ntree(5, tree(2, nil, tree(3, nil, nil)), tree(9, nil, tree(10, nil, tree(11, nil, nil))))\\n```\\n\\n比较这个最终结果与给定的选项，可以看到选项 B 正确地描述了结果树的结构。\\n\\n答案是：B',\n",
       "  '根据题目描述的函数逻辑，我们来逐步分析输入列表 [3,7,5,9] 的处理过程：\\n\\n1. 列表非空，开始处理第一个元素3。\\n2. 3是奇数，根据规则应被删除。\\n3. 处理下一个元素7，同样为奇数，删除。\\n4. 继续处理5，同样是奇数，删除。\\n5. 最后处理9，依然是奇数，删除。\\n\\n整个过程中，由于输入列表中的所有元素都是奇数，根据规则它们都将被删除，不会有任何元素保留在结果列表中。\\n\\n因此，对于输入列表 [3,7,5,9]，函数返回的结果是空列表。\\n\\n答案是：D. []',\n",
       "  '为了回答这个问题，我们首先需要根据斐波那契数列的定义来计算前几个数字：\\n\\n1. 第0个数字是1。\\n2. 第1个数字是1。\\n3. 第2个数字是第0个数字（1）加上第1个数字（1），等于2。\\n4. 第3个数字是第1个数字（1）加上第2个数字（2），等于3。\\n5. 第4个数字是第2个数字（2）加上第3个数字（3），等于5。\\n\\n因此，斐波那契数列中的第4个数字是5，不是1。\\n\\n答案是：B. 不是'],\n",
       " '__index_level_0__': [0, 1, 2]}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d94d5b5d-3aed-4e31-b475-318b94d5e922",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-27T15:24:59.126700Z",
     "iopub.status.busy": "2024-07-27T15:24:59.126411Z",
     "iopub.status.idle": "2024-07-27T15:24:59.314870Z",
     "shell.execute_reply": "2024-07-27T15:24:59.314270Z",
     "shell.execute_reply.started": "2024-07-27T15:24:59.126682Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Qwen2Tokenizer(name_or_path='./qwen/Qwen2-7B-Instruct', vocab_size=151643, model_max_length=131072, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'eos_token': '<|im_end|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>']}, clean_up_tokenization_spaces=False),  added_tokens_decoder={\n",
       "\t151643: AddedToken(\"<|endoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t151644: AddedToken(\"<|im_start|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t151645: AddedToken(\"<|im_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('./qwen/Qwen2-7B-Instruct', use_fast=False, trust_remote_code=True)\n",
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f6deea5-d94f-4b23-88fa-2eb2d9f3f74a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-27T15:25:00.198564Z",
     "iopub.status.busy": "2024-07-27T15:25:00.198253Z",
     "iopub.status.idle": "2024-07-27T15:25:00.203028Z",
     "shell.execute_reply": "2024-07-27T15:25:00.202348Z",
     "shell.execute_reply.started": "2024-07-27T15:25:00.198547Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def process_func(example):\n",
    "    MAX_LENGTH = 1800    # Llama分词器会将一个中文字切分为多个token，因此需要放开一些最大长度，保证数据的完整性\n",
    "    input_ids, attention_mask, labels = [], [], []\n",
    "    instruction = tokenizer(f\"<|im_start|>system\\n你是一个逻辑推理专家，擅长解决逻辑推理问题。<|im_end|>\\n<|im_start|>user\\n{example['instruction'] + example['input']}<|im_end|>\\n<|im_start|>assistant\\n\", add_special_tokens=False)  # add_special_tokens 不在开头加 special_tokens\n",
    "    response = tokenizer(f\"{example['output']}\", add_special_tokens=False)\n",
    "    input_ids = instruction[\"input_ids\"] + response[\"input_ids\"] + [tokenizer.pad_token_id]\n",
    "    attention_mask = instruction[\"attention_mask\"] + response[\"attention_mask\"] + [1]  # 因为eos token咱们也是要关注的所以 补充为1\n",
    "    labels = [-100] * len(instruction[\"input_ids\"]) + response[\"input_ids\"] + [tokenizer.pad_token_id]  \n",
    "    if len(input_ids) > MAX_LENGTH:  # 做一个截断\n",
    "        input_ids = input_ids[:MAX_LENGTH]\n",
    "        attention_mask = attention_mask[:MAX_LENGTH]\n",
    "        labels = labels[:MAX_LENGTH]\n",
    "    return {\n",
    "        \"input_ids\": input_ids,\n",
    "        \"attention_mask\": attention_mask,\n",
    "        \"labels\": labels\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3cf900c4-9257-450b-bf07-0084fc46634f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-27T15:25:00.966985Z",
     "iopub.status.busy": "2024-07-27T15:25:00.966683Z",
     "iopub.status.idle": "2024-07-27T15:25:09.603337Z",
     "shell.execute_reply": "2024-07-27T15:25:09.602885Z",
     "shell.execute_reply.started": "2024-07-27T15:25:00.966967Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1204/1204 [00:06<00:00, 197.08 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_ids', 'attention_mask', 'labels'],\n",
       "    num_rows: 1204\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_id = ds.map(process_func, remove_columns=ds.column_names)\n",
    "tokenized_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3c28a3b3-4688-42d2-9d18-55e6a00e70b4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-27T15:25:11.405386Z",
     "iopub.status.busy": "2024-07-27T15:25:11.405053Z",
     "iopub.status.idle": "2024-07-27T15:25:11.414868Z",
     "shell.execute_reply": "2024-07-27T15:25:11.414381Z",
     "shell.execute_reply.started": "2024-07-27T15:25:11.405368Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|im_start|>system\\n你是一个逻辑推理专家，擅长解决逻辑推理问题。<|im_end|>\\n<|im_start|>user\\n你是一个逻辑推理专家，擅长解决逻辑推理问题。以下是一个逻辑推理的题目，形式为单项选择题。所有的问题都是（close-world assumption）闭世界假设，即未观测事实都为假。请逐步分析问题并在最后一行输出答案，最后一行的格式为\"答案是：A\"。题目如下：\\n\\n### 题目:\\n假设您需要构建一个二叉搜索树，其中每个节点或者是一个空的节点（称为\"空节点\"），或者是一个包含一个整数值和两个子树的节点（称为\"数值节点\"）。以下是构建这棵树的规则：\\n\\n1. 树中不存在重复的元素。\\n2. 对于每个数值节点，其左子树的所有值都小于该节点的值，其右子树的所有值都大于该节点的值。\\n3. 插入一个新值到一个\"空节点\"时，该\"空节点\"会被一个包含新值的新的数值节点取代。\\n4. 插入一个已存在的数值将不会改变树。\\n\\n请基于以上规则，回答以下选择题：\\n\\n### 问题:\\n选择题 1：\\n给定一个空的二叉搜索树，插入下列数字: [5, 9, 2, 10, 11, 3]，下面哪个选项正确描述了结果树的结构？\\nA. tree(5, tree(2, tree(3, nil, nil), nil), tree(9, tree(10, nil, nil), tree(11, nil, nil)))\\nB. tree(5, tree(2, nil, tree(3, nil, nil)), tree(9, nil, tree(10, nil, tree(11, nil, nil))))\\nC. tree(5, tree(3, tree(2, nil, nil), nil), tree(9, nil, tree(10, tree(11, nil, nil), nil)))\\nD. tree(5, nil, tree(2, nil, tree(3, nil, nil)), tree(9, tree(11, nil, nil), tree(10, nil, nil)))\\n<|im_end|>\\n<|im_start|>assistant\\n根据题目中的规则，我们依次插入数字 [5, 9, 2, 10, 11, 3] 来构建二叉搜索树。\\n\\n首先插入数字 5，树为：\\n```\\ntree(5, nil, nil)\\n```\\n\\n然后插入数字 9，由于 9 > 5，因此插入到右子树：\\n```\\ntree(5, nil, tree(9, nil, nil))\\n```\\n\\n接下来插入数字 2，由于 2 < 5，因此插入到左子树：\\n```\\ntree(5, tree(2, nil, nil), tree(9, nil, nil))\\n```\\n\\n再插入数字 10，由于 10 > 5 并且 10 > 9，所以插入到 9 的右子树：\\n```\\ntree(5, tree(2, nil, nil), tree(9, nil, tree(10, nil, nil)))\\n```\\n\\n继续插入数字 11，由于 11 > 5 并且 11 > 9 和 11 > 10，所以插入到 10 的右子树：\\n```\\ntree(5, tree(2, nil, nil), tree(9, nil, tree(10, nil, tree(11, nil, nil))))\\n```\\n\\n最后插入数字 3，由于 3 < 5 但是 3 > 2，所以插入到 2 的右子树：\\n```\\ntree(5, tree(2, nil, tree(3, nil, nil)), tree(9, nil, tree(10, nil, tree(11, nil, nil))))\\n```\\n\\n比较这个最终结果与给定的选项，可以看到选项 B 正确地描述了结果树的结构。\\n\\n答案是：B<|endoftext|>'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(tokenized_id[0]['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7a3325fb-487b-4dd6-9fdb-8a7abbf5b8b0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-27T15:25:13.652481Z",
     "iopub.status.busy": "2024-07-27T15:25:13.652174Z",
     "iopub.status.idle": "2024-07-27T15:25:13.657627Z",
     "shell.execute_reply": "2024-07-27T15:25:13.657204Z",
     "shell.execute_reply.started": "2024-07-27T15:25:13.652462Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'根据题目描述的函数逻辑，我们来逐步分析输入列表 [3,7,5,9] 的处理过程：\\n\\n1. 列表非空，开始处理第一个元素3。\\n2. 3是奇数，根据规则应被删除。\\n3. 处理下一个元素7，同样为奇数，删除。\\n4. 继续处理5，同样是奇数，删除。\\n5. 最后处理9，依然是奇数，删除。\\n\\n整个过程中，由于输入列表中的所有元素都是奇数，根据规则它们都将被删除，不会有任何元素保留在结果列表中。\\n\\n因此，对于输入列表 [3,7,5,9]，函数返回的结果是空列表。\\n\\n答案是：D. []<|endoftext|>'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(list(filter(lambda x: x != -100, tokenized_id[1][\"labels\"])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d514a730-3af3-444c-94f3-9a03a6f1ccf2",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-07-27T15:25:14.373031Z",
     "iopub.status.busy": "2024-07-27T15:25:14.372721Z",
     "iopub.status.idle": "2024-07-27T15:25:58.435349Z",
     "shell.execute_reply": "2024-07-27T15:25:58.434861Z",
     "shell.execute_reply.started": "2024-07-27T15:25:14.373014Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:40<00:00, 10.20s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Qwen2ForCausalLM(\n",
       "  (model): Qwen2Model(\n",
       "    (embed_tokens): Embedding(152064, 3584)\n",
       "    (layers): ModuleList(\n",
       "      (0-27): 28 x Qwen2DecoderLayer(\n",
       "        (self_attn): Qwen2SdpaAttention(\n",
       "          (q_proj): Linear(in_features=3584, out_features=3584, bias=True)\n",
       "          (k_proj): Linear(in_features=3584, out_features=512, bias=True)\n",
       "          (v_proj): Linear(in_features=3584, out_features=512, bias=True)\n",
       "          (o_proj): Linear(in_features=3584, out_features=3584, bias=False)\n",
       "          (rotary_emb): Qwen2RotaryEmbedding()\n",
       "        )\n",
       "        (mlp): Qwen2MLP(\n",
       "          (gate_proj): Linear(in_features=3584, out_features=18944, bias=False)\n",
       "          (up_proj): Linear(in_features=3584, out_features=18944, bias=False)\n",
       "          (down_proj): Linear(in_features=18944, out_features=3584, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): Qwen2RMSNorm()\n",
       "        (post_attention_layernorm): Qwen2RMSNorm()\n",
       "      )\n",
       "    )\n",
       "    (norm): Qwen2RMSNorm()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=3584, out_features=152064, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained('./qwen/Qwen2-7B-Instruct', device_map=\"auto\",torch_dtype=torch.bfloat16)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "51fe0c77-a538-45b8-aa9f-14f3ef2306cd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-27T15:25:58.436541Z",
     "iopub.status.busy": "2024-07-27T15:25:58.436277Z",
     "iopub.status.idle": "2024-07-27T15:25:58.439911Z",
     "shell.execute_reply": "2024-07-27T15:25:58.439408Z",
     "shell.execute_reply.started": "2024-07-27T15:25:58.436522Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.enable_input_require_grads() # 开启梯度检查点时，要执行该方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f5dca344-f91f-4f98-94a6-c742bdaf15e8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-27T15:25:58.440826Z",
     "iopub.status.busy": "2024-07-27T15:25:58.440621Z",
     "iopub.status.idle": "2024-07-27T15:25:58.445365Z",
     "shell.execute_reply": "2024-07-27T15:25:58.444921Z",
     "shell.execute_reply.started": "2024-07-27T15:25:58.440812Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.bfloat16"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f51b7493-83d9-4489-bdb9-fdac20386dae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-27T15:25:58.446664Z",
     "iopub.status.busy": "2024-07-27T15:25:58.446479Z",
     "iopub.status.idle": "2024-07-27T15:25:58.450428Z",
     "shell.execute_reply": "2024-07-27T15:25:58.449977Z",
     "shell.execute_reply.started": "2024-07-27T15:25:58.446650Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LoraConfig(peft_type=<PeftType.LORA: 'LORA'>, auto_mapping=None, base_model_name_or_path=None, revision=None, task_type=<TaskType.CAUSAL_LM: 'CAUSAL_LM'>, inference_mode=False, r=8, target_modules={'down_proj', 'v_proj', 'gate_proj', 'up_proj', 'k_proj', 'q_proj', 'o_proj'}, lora_alpha=32, lora_dropout=0.1, fan_in_fan_out=False, bias='none', use_rslora=False, modules_to_save=None, init_lora_weights=True, layers_to_transform=None, layers_pattern=None, rank_pattern={}, alpha_pattern={}, megatron_config=None, megatron_core='megatron.core', loftq_config={}, use_dora=False, layer_replication=None)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from peft import LoraConfig, TaskType, get_peft_model\n",
    "\n",
    "config = LoraConfig(\n",
    "    task_type=TaskType.CAUSAL_LM, \n",
    "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"],\n",
    "    inference_mode=False, # 训练模式\n",
    "    r=8, # Lora 秩\n",
    "    lora_alpha=32, # Lora alaph，具体作用参见 Lora 原理\n",
    "    lora_dropout=0.1# Dropout 比例\n",
    ")\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eff0aed7-9726-45a8-be09-1e20b9342838",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-27T15:25:58.451160Z",
     "iopub.status.busy": "2024-07-27T15:25:58.450958Z",
     "iopub.status.idle": "2024-07-27T15:25:59.162789Z",
     "shell.execute_reply": "2024-07-27T15:25:59.162196Z",
     "shell.execute_reply.started": "2024-07-27T15:25:58.451144Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LoraConfig(peft_type=<PeftType.LORA: 'LORA'>, auto_mapping=None, base_model_name_or_path='./qwen/Qwen2-7B-Instruct', revision=None, task_type=<TaskType.CAUSAL_LM: 'CAUSAL_LM'>, inference_mode=False, r=8, target_modules={'down_proj', 'v_proj', 'gate_proj', 'up_proj', 'k_proj', 'q_proj', 'o_proj'}, lora_alpha=32, lora_dropout=0.1, fan_in_fan_out=False, bias='none', use_rslora=False, modules_to_save=None, init_lora_weights=True, layers_to_transform=None, layers_pattern=None, rank_pattern={}, alpha_pattern={}, megatron_config=None, megatron_core='megatron.core', loftq_config={}, use_dora=False, layer_replication=None)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_peft_model(model, config)\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d3a74f48-3823-4ab8-8362-4a37416d66fb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-27T15:25:59.163725Z",
     "iopub.status.busy": "2024-07-27T15:25:59.163490Z",
     "iopub.status.idle": "2024-07-27T15:25:59.170009Z",
     "shell.execute_reply": "2024-07-27T15:25:59.169528Z",
     "shell.execute_reply.started": "2024-07-27T15:25:59.163708Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 20,185,088 || all params: 7,635,801,600 || trainable%: 0.26434798934534914\n"
     ]
    }
   ],
   "source": [
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "679a6e7d-e85d-4a6b-96fa-0deb601b62e0",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-07-27T15:25:59.170858Z",
     "iopub.status.busy": "2024-07-27T15:25:59.170656Z",
     "iopub.status.idle": "2024-07-27T15:25:59.182887Z",
     "shell.execute_reply": "2024-07-27T15:25:59.182488Z",
     "shell.execute_reply.started": "2024-07-27T15:25:59.170844Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "args = TrainingArguments(\n",
    "    output_dir=\"./output/Qwen2_instruct_lora\",\n",
    "    per_device_train_batch_size=1,\n",
    "    gradient_accumulation_steps=4,\n",
    "    logging_steps=10,\n",
    "    num_train_epochs=1,\n",
    "    save_steps=100, # 为了快速演示，这里设置10，建议你设置成100\n",
    "    learning_rate=1e-4,\n",
    "    save_on_each_node=True,\n",
    "    gradient_checkpointing=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9b90ef0a-7bfb-4252-a899-6b2c44972a9a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-27T15:25:59.183628Z",
     "iopub.status.busy": "2024-07-27T15:25:59.183447Z",
     "iopub.status.idle": "2024-07-27T15:25:59.235050Z",
     "shell.execute_reply": "2024-07-27T15:25:59.234596Z",
     "shell.execute_reply.started": "2024-07-27T15:25:59.183614Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 4.19.91, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=tokenized_id,\n",
    "    data_collator=DataCollatorForSeq2Seq(tokenizer=tokenizer, padding=True),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "20463028-64c9-4ebe-98a9-512fe3530593",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-27T15:25:59.235807Z",
     "iopub.status.busy": "2024-07-27T15:25:59.235631Z",
     "iopub.status.idle": "2024-07-27T15:25:59.238230Z",
     "shell.execute_reply": "2024-07-27T15:25:59.237704Z",
     "shell.execute_reply.started": "2024-07-27T15:25:59.235793Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.backends.cuda.enable_mem_efficient_sdp(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2b59bf7e-7d47-4973-bd6a-718da07cc650",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-27T15:26:18.753267Z",
     "iopub.status.busy": "2024-07-27T15:26:18.752959Z",
     "iopub.status.idle": "2024-07-27T15:37:03.079543Z",
     "shell.execute_reply": "2024-07-27T15:37:03.079094Z",
     "shell.execute_reply.started": "2024-07-27T15:26:18.753249Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-07-27 23:26:19,017] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n",
      "\n",
      "/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='301' max='301' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [301/301 10:40, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.670800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.574900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.626100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.591700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.575300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.644400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.577500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.601700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.485900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.583000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.592700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.540600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.597700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.509000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.620700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.530400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.519800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.576700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.528600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.609000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.604700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.569100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.603400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.555200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.542100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.521900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.625300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.523800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.539200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.554900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in ./qwen/Qwen2-7B-Instruct - will assume that the vocabulary was not modified.\n",
      "\n",
      "  warnings.warn(\n",
      "\n",
      "/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "\n",
      "  warnings.warn(\n",
      "\n",
      "/opt/conda/lib/python3.10/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in ./qwen/Qwen2-7B-Instruct - will assume that the vocabulary was not modified.\n",
      "\n",
      "  warnings.warn(\n",
      "\n",
      "/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "\n",
      "  warnings.warn(\n",
      "\n",
      "/opt/conda/lib/python3.10/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in ./qwen/Qwen2-7B-Instruct - will assume that the vocabulary was not modified.\n",
      "\n",
      "  warnings.warn(\n",
      "\n",
      "/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "\n",
      "  warnings.warn(\n",
      "\n",
      "/opt/conda/lib/python3.10/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in ./qwen/Qwen2-7B-Instruct - will assume that the vocabulary was not modified.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=301, training_loss=0.5728449522458834, metrics={'train_runtime': 643.6899, 'train_samples_per_second': 1.87, 'train_steps_per_second': 0.468, 'total_flos': 2.335115283830784e+16, 'train_loss': 0.5728449522458834, 'epoch': 1.0})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10a79d04-7a2a-4711-8f22-c599a0fe6d65",
   "metadata": {},
   "source": [
    "## 这里运行完请重启notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "743e2e1b-3108-432e-be38-2597332221cf",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-07-27T16:15:26.199740Z",
     "iopub.status.busy": "2024-07-27T16:15:26.199558Z",
     "iopub.status.idle": "2024-07-27T16:16:24.698704Z",
     "shell.execute_reply": "2024-07-27T16:16:24.698195Z",
     "shell.execute_reply.started": "2024-07-27T16:15:26.199723Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "\n",
      "2024-07-28 00:15:33.460211: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "\n",
      "2024-07-28 00:15:33.658560: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "\n",
      "2024-07-28 00:15:33.751489: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "\n",
      "2024-07-28 00:15:33.774577: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "\n",
      "2024-07-28 00:15:33.923242: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\n",
      "2024-07-28 00:15:34.902958: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:40<00:00, 10.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "from peft import PeftModel\n",
    "\n",
    "mode_path = './qwen/Qwen2-7B-Instruct/'\n",
    "lora_path = './output/Qwen2_instruct_lora_an/checkpoint-100' # 这里改称你的 lora 输出对应 checkpoint 地址\n",
    "\n",
    "# 加载tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(mode_path, trust_remote_code=True)\n",
    "\n",
    "# 加载模型\n",
    "model = AutoModelForCausalLM.from_pretrained(mode_path, device_map=\"auto\",torch_dtype=torch.float16, trust_remote_code=True).eval()\n",
    "\n",
    "# 加载lora权重\n",
    "model = PeftModel.from_pretrained(model, model_id=lora_path)\n",
    "\n",
    "prompt = '''你是一个逻辑推理专家，擅长解决逻辑推理问题。以下是一个逻辑推理的题目，形式为单项选择题。所有的问题都是（close-world assumption）闭世界假设，即未观测事实都为假。请逐步分析问题并在最后一行输出答案，最后一行的格式为\"答案是：A\"。题目如下：\\n\\n### 题目:\\n假设您需要构建一个二叉搜索树，其中每个节点或者是一个空的节点（称为\"空节点\"），或者是一个包含一个整数值和两个子树的节点（称为\"数值节点\"）。以下是构建这棵树的规则：\\n\\n1. 树中不存在重复的元素。\\n2. 对于每个数值节点，其左子树的所有值都小于该节点的值，其右子树的所有值都大于该节点的值。\\n3. 插入一个新值到一个\"空节点\"时，该\"空节点\"会被一个包含新值的新的数值节点取代。\\n4. 插入一个已存在的数值将不会改变树。\\n\\n请基于以上规则，回答以下选择题：\\n\\n### 问题:\\n选择题 1：\\n给定一个空的二叉搜索树，插入下列数字: [5, 9, 2, 10, 11, 3]，下面哪个选项正确描述了结果树的结构？\\nA. tree(5, tree(2, tree(3, nil, nil), nil), tree(9, tree(10, nil, nil), tree(11, nil, nil)))\\nB. tree(5, tree(2, nil, tree(3, nil, nil)), tree(9, nil, tree(10, nil, tree(11, nil, nil))))\\nC. tree(5, tree(3, tree(2, nil, nil), nil), tree(9, nil, tree(10, tree(11, nil, nil), nil)))\\nD. tree(5, nil, tree(2, nil, tree(3, nil, nil)), tree(9, tree(11, nil, nil), tree(10, nil, nil)))'''\n",
    "inputs = tokenizer.apply_chat_template([{\"role\": \"user\", \"content\": \"你是一个逻辑推理专家，擅长解决逻辑推理问题。\"},{\"role\": \"user\", \"content\": prompt}],\n",
    "                                       add_generation_prompt=True,\n",
    "                                       tokenize=True,\n",
    "                                       return_tensors=\"pt\",\n",
    "                                       return_dict=True\n",
    "                                       ).to('cuda')\n",
    "\n",
    "\n",
    "gen_kwargs = {\"max_length\": 2500, \"do_sample\": True, \"top_k\": 1}\n",
    "with torch.no_grad():\n",
    "    outputs = model.generate(**inputs, **gen_kwargs)\n",
    "    outputs = outputs[:, inputs['input_ids'].shape[1]:]\n",
    "    print(tokenizer.decode(outputs[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dfa947a0-9830-4d21-8b3d-3e0116ec13c1",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-07-27T16:16:39.950973Z",
     "iopub.status.busy": "2024-07-27T16:16:39.950661Z",
     "iopub.status.idle": "2024-07-27T16:17:16.352942Z",
     "shell.execute_reply": "2024-07-27T16:17:16.352287Z",
     "shell.execute_reply.started": "2024-07-27T16:16:39.950954Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 模型合并存储\n",
    "\n",
    "new_model_directory = \"./merged_model_an\"\n",
    "merged_model = model.merge_and_unload()\n",
    "# 将权重保存为safetensors格式的权重, 且每个权重文件最大不超过2GB(2048MB)\n",
    "merged_model.save_pretrained(new_model_directory, max_shard_size=\"2048MB\", safe_serialization=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e6efba9-0d26-4e5c-908b-df42ea78c5c8",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-07-27T16:17:32.549954Z",
     "iopub.status.busy": "2024-07-27T16:17:32.549625Z",
     "iopub.status.idle": "2024-07-27T16:17:34.724805Z",
     "shell.execute_reply": "2024-07-27T16:17:34.724217Z",
     "shell.execute_reply.started": "2024-07-27T16:17:32.549935Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "\n",
      "To disable this warning, you can either:\n",
      "\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "!cp ./qwen/Qwen2-7B-Instruct/tokenizer.json ./merged_model_an/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86cd2323-d732-4e15-963b-c51e1975401f",
   "metadata": {},
   "source": [
    "## 这里运行完请重启notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "04b4e63f-1488-4417-8060-b68a65b64803",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-15T10:03:16.463102Z",
     "iopub.status.busy": "2024-08-15T10:03:16.462779Z",
     "iopub.status.idle": "2024-08-15T10:03:25.746016Z",
     "shell.execute_reply": "2024-08-15T10:03:25.745272Z",
     "shell.execute_reply.started": "2024-08-15T10:03:16.463080Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-15 18:03:21,452 - modelscope - INFO - Downloading to /mnt/workspace/.cache/modelscope/hub/datasets/952a8ad65c92b0c877718d9b3b48fd570e5e8b8428ef63dafa282f3a4388b11a.incomplete\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3a0eeac913b4a84a482ab7c0965db9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/406 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-15 18:03:22,205 - modelscope - INFO - storing https://www.modelscope.cn/api/v1/datasets/Datawhale/DW2024_Complex_reasoning_ability_assessment_qwen2-7b-lora/repo?Source=SDK&Revision=master&FilePath=README.md&View=False in cache at /mnt/workspace/.cache/modelscope/hub/datasets/952a8ad65c92b0c877718d9b3b48fd570e5e8b8428ef63dafa282f3a4388b11a\n",
      "2024-08-15 18:03:22,206 - modelscope - INFO - creating metadata file for /mnt/workspace/.cache/modelscope/hub/datasets/952a8ad65c92b0c877718d9b3b48fd570e5e8b8428ef63dafa282f3a4388b11a\n",
      "2024-08-15 18:03:25,138 - modelscope - INFO - Some files matched the pattern 'hf://datasets/Datawhale/DW2024_Complex_reasoning_ability_assessment_qwen2-7b-lora@master/**/training[-._ 0-9]*' but don't have valid data file extensions: ['hf://datasets/Datawhale/DW2024_Complex_reasoning_ability_assessment_qwen2-7b-lora@master/output/Qwen2_instruct_lora_an/checkpoint-100/training_args.bin', 'hf://datasets/Datawhale/DW2024_Complex_reasoning_ability_assessment_qwen2-7b-lora@master/output/Qwen2_instruct_lora_ana/checkpoint-100/training_args.bin']\n"
     ]
    },
    {
     "ename": "DataFilesNotFoundError",
     "evalue": "No (supported) data files found in Datawhale/DW2024_Complex_reasoning_ability_assessment_qwen2-7b-lora",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mDataFilesNotFoundError\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#数据集下载\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmodelscope\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmsdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MsDataset\n\u001b[0;32m----> 3\u001b[0m ds \u001b[38;5;241m=\u001b[39m  \u001b[43mMsDataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mDatawhale/DW2024_Complex_reasoning_ability_assessment_qwen2-7b-lora\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m#您可按需配置 subset_name、split，参照“快速使用”示例代码\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/modelscope/msdatasets/ms_dataset.py:292\u001b[0m, in \u001b[0;36mMsDataset.load\u001b[0;34m(dataset_name, namespace, target, version, hub, subset_name, split, data_dir, data_files, download_mode, cache_dir, use_streaming, stream_batch_size, custom_cfg, token, dataset_info_only, **config_kwargs)\u001b[0m\n\u001b[1;32m    289\u001b[0m \u001b[38;5;66;03m# Load from the ModelScope Hub for type=4 (general)\u001b[39;00m\n\u001b[1;32m    290\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(dataset_type) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mstr\u001b[39m(DatasetFormations\u001b[38;5;241m.\u001b[39mgeneral\u001b[38;5;241m.\u001b[39mvalue):\n\u001b[0;32m--> 292\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m load_dataset_with_ctx(\n\u001b[1;32m    293\u001b[0m             path\u001b[38;5;241m=\u001b[39mnamespace \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m dataset_name,\n\u001b[1;32m    294\u001b[0m             name\u001b[38;5;241m=\u001b[39msubset_name,\n\u001b[1;32m    295\u001b[0m             data_dir\u001b[38;5;241m=\u001b[39mdata_dir,\n\u001b[1;32m    296\u001b[0m             data_files\u001b[38;5;241m=\u001b[39mdata_files,\n\u001b[1;32m    297\u001b[0m             split\u001b[38;5;241m=\u001b[39msplit,\n\u001b[1;32m    298\u001b[0m             cache_dir\u001b[38;5;241m=\u001b[39mcache_dir,\n\u001b[1;32m    299\u001b[0m             features\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    300\u001b[0m             download_config\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    301\u001b[0m             download_mode\u001b[38;5;241m=\u001b[39mdownload_mode\u001b[38;5;241m.\u001b[39mvalue,\n\u001b[1;32m    302\u001b[0m             revision\u001b[38;5;241m=\u001b[39mversion,\n\u001b[1;32m    303\u001b[0m             token\u001b[38;5;241m=\u001b[39mtoken,\n\u001b[1;32m    304\u001b[0m             streaming\u001b[38;5;241m=\u001b[39muse_streaming,\n\u001b[1;32m    305\u001b[0m             dataset_info_only\u001b[38;5;241m=\u001b[39mdataset_info_only,\n\u001b[1;32m    306\u001b[0m             trust_remote_code\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    307\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig_kwargs) \u001b[38;5;28;01mas\u001b[39;00m dataset_res:\n\u001b[1;32m    309\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m dataset_res\n\u001b[1;32m    311\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/contextlib.py:135\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 135\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m    137\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgenerator didn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt yield\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/modelscope/msdatasets/utils/hf_datasets_util.py:1364\u001b[0m, in \u001b[0;36mload_dataset_with_ctx\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1361\u001b[0m HubDatasetModuleFactoryWithScript\u001b[38;5;241m.\u001b[39mget_module \u001b[38;5;241m=\u001b[39m get_module_with_script\n\u001b[1;32m   1363\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1364\u001b[0m     dataset_res \u001b[38;5;241m=\u001b[39m \u001b[43mDatasetsWrapperHF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1365\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m dataset_res\n\u001b[1;32m   1366\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/modelscope/msdatasets/utils/hf_datasets_util.py:937\u001b[0m, in \u001b[0;36mDatasetsWrapperHF.load_dataset\u001b[0;34m(path, name, data_dir, data_files, split, cache_dir, features, download_config, download_mode, verification_mode, ignore_verifications, keep_in_memory, save_infos, revision, token, use_auth_token, task, streaming, num_proc, storage_options, trust_remote_code, dataset_info_only, **config_kwargs)\u001b[0m\n\u001b[1;32m    932\u001b[0m verification_mode \u001b[38;5;241m=\u001b[39m VerificationMode((\n\u001b[1;32m    933\u001b[0m     verification_mode \u001b[38;5;129;01mor\u001b[39;00m VerificationMode\u001b[38;5;241m.\u001b[39mBASIC_CHECKS\n\u001b[1;32m    934\u001b[0m ) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m save_infos \u001b[38;5;28;01melse\u001b[39;00m VerificationMode\u001b[38;5;241m.\u001b[39mALL_CHECKS)\n\u001b[1;32m    936\u001b[0m \u001b[38;5;66;03m# Create a dataset builder\u001b[39;00m\n\u001b[0;32m--> 937\u001b[0m builder_instance \u001b[38;5;241m=\u001b[39m \u001b[43mDatasetsWrapperHF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_dataset_builder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    938\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    939\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    940\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    941\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_files\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_files\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    942\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    943\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    944\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    945\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdownload_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    946\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    947\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    948\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    949\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    950\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_require_default_config_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    951\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mconfig_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    952\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    954\u001b[0m \u001b[38;5;66;03m# Note: Only for preview mode\u001b[39;00m\n\u001b[1;32m    955\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dataset_info_only:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/modelscope/msdatasets/utils/hf_datasets_util.py:1064\u001b[0m, in \u001b[0;36mDatasetsWrapperHF.load_dataset_builder\u001b[0;34m(path, name, data_dir, data_files, cache_dir, features, download_config, download_mode, revision, token, use_auth_token, storage_options, trust_remote_code, _require_default_config_name, **config_kwargs)\u001b[0m\n\u001b[1;32m   1060\u001b[0m     download_config \u001b[38;5;241m=\u001b[39m download_config\u001b[38;5;241m.\u001b[39mcopy(\n\u001b[1;32m   1061\u001b[0m     ) \u001b[38;5;28;01mif\u001b[39;00m download_config \u001b[38;5;28;01melse\u001b[39;00m DownloadConfig()\n\u001b[1;32m   1062\u001b[0m     download_config\u001b[38;5;241m.\u001b[39mstorage_options\u001b[38;5;241m.\u001b[39mupdate(storage_options)\n\u001b[0;32m-> 1064\u001b[0m dataset_module \u001b[38;5;241m=\u001b[39m \u001b[43mDatasetsWrapperHF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset_module_factory\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1065\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1066\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1067\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1068\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdownload_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1069\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1070\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_files\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_files\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1071\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1072\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1073\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_require_default_config_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_require_default_config_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1074\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_require_custom_configs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mbool\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mconfig_kwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1075\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1076\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1077\u001b[0m \u001b[38;5;66;03m# Get dataset builder class from the processing script\u001b[39;00m\n\u001b[1;32m   1078\u001b[0m builder_kwargs \u001b[38;5;241m=\u001b[39m dataset_module\u001b[38;5;241m.\u001b[39mbuilder_kwargs\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/modelscope/msdatasets/utils/hf_datasets_util.py:1317\u001b[0m, in \u001b[0;36mDatasetsWrapperHF.dataset_module_factory\u001b[0;34m(path, revision, download_config, download_mode, dynamic_modules_path, data_dir, data_files, cache_dir, trust_remote_code, _require_default_config_name, _require_custom_configs, **download_kwargs)\u001b[0m\n\u001b[1;32m   1311\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(\n\u001b[1;32m   1312\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCouldn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt reach the Hugging Face Hub for dataset \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me1\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1313\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1314\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e1,\n\u001b[1;32m   1315\u001b[0m               (DataFilesNotFoundError,\n\u001b[1;32m   1316\u001b[0m                DatasetNotFoundError, EmptyDatasetError)):\n\u001b[0;32m-> 1317\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e1 \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1318\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e1, \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m):\n\u001b[1;32m   1319\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\n\u001b[1;32m   1320\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCouldn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt find a dataset script at \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrelative_to_absolute_path(combined_path)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m or \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1321\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124many data file in the same directory. \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   1322\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCouldn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt find \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m on the Hugging Face Hub either: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(e1)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me1\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1323\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/modelscope/msdatasets/utils/hf_datasets_util.py:1300\u001b[0m, in \u001b[0;36mDatasetsWrapperHF.dataset_module_factory\u001b[0;34m(path, revision, download_config, download_mode, dynamic_modules_path, data_dir, data_files, cache_dir, trust_remote_code, _require_default_config_name, _require_custom_configs, **download_kwargs)\u001b[0m\n\u001b[1;32m   1284\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m HubDatasetModuleFactoryWithScript(\n\u001b[1;32m   1285\u001b[0m             path,\n\u001b[1;32m   1286\u001b[0m             revision\u001b[38;5;241m=\u001b[39mrevision,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1290\u001b[0m             trust_remote_code\u001b[38;5;241m=\u001b[39mtrust_remote_code,\n\u001b[1;32m   1291\u001b[0m         )\u001b[38;5;241m.\u001b[39mget_module()\n\u001b[1;32m   1292\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1293\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mHubDatasetModuleFactoryWithoutScript\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1294\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1295\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1296\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1297\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdata_files\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_files\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1298\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1299\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdownload_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m-> 1300\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1301\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e1:\n\u001b[1;32m   1302\u001b[0m     \u001b[38;5;66;03m# All the attempts failed, before raising the error we should check if the module is already cached\u001b[39;00m\n\u001b[1;32m   1303\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/modelscope/msdatasets/utils/hf_datasets_util.py:600\u001b[0m, in \u001b[0;36mget_module_without_script\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    591\u001b[0m     patterns \u001b[38;5;241m=\u001b[39m _get_data_patterns(\n\u001b[1;32m    592\u001b[0m         base_path, download_config\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdownload_config)\n\u001b[1;32m    594\u001b[0m data_files \u001b[38;5;241m=\u001b[39m DataFilesDict\u001b[38;5;241m.\u001b[39mfrom_patterns(\n\u001b[1;32m    595\u001b[0m     patterns,\n\u001b[1;32m    596\u001b[0m     base_path\u001b[38;5;241m=\u001b[39mbase_path,\n\u001b[1;32m    597\u001b[0m     allowed_extensions\u001b[38;5;241m=\u001b[39mALL_ALLOWED_EXTENSIONS,\n\u001b[1;32m    598\u001b[0m     download_config\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdownload_config,\n\u001b[1;32m    599\u001b[0m )\n\u001b[0;32m--> 600\u001b[0m module_name, default_builder_kwargs \u001b[38;5;241m=\u001b[39m \u001b[43minfer_module_for_data_files\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    601\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_files\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_files\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    602\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    603\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownload_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    604\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    605\u001b[0m data_files \u001b[38;5;241m=\u001b[39m data_files\u001b[38;5;241m.\u001b[39mfilter_extensions(\n\u001b[1;32m    606\u001b[0m     _MODULE_TO_EXTENSIONS[module_name])\n\u001b[1;32m    607\u001b[0m \u001b[38;5;66;03m# Collect metadata files if the module supports them\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/datasets/load.py:595\u001b[0m, in \u001b[0;36minfer_module_for_data_files\u001b[0;34m(data_files, path, download_config)\u001b[0m\n\u001b[1;32m    593\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCouldn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt infer the same data file format for all splits. Got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msplit_modules\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    594\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m module_name:\n\u001b[0;32m--> 595\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m DataFilesNotFoundError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo (supported) data files found\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m (\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m path \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m    596\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module_name, default_builder_kwargs\n",
      "\u001b[0;31mDataFilesNotFoundError\u001b[0m: No (supported) data files found in Datawhale/DW2024_Complex_reasoning_ability_assessment_qwen2-7b-lora"
     ]
    }
   ],
   "source": [
    "#数据集下载\n",
    "from modelscope.msdatasets import MsDataset\n",
    "ds =  MsDataset.load('Datawhale/DW2024_Complex_reasoning_ability_assessment_qwen2-7b-lora')\n",
    "#您可按需配置 subset_name、split，参照“快速使用”示例代码"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
